% TEMPLATE for Usenix papers, specifically to meet requirements of
%  USENIX '05
% originally a template for producing IEEE-format articles using LaTeX.
%   written by Matthew Ward, CS Department, Worcester Polytechnic Institute.
% adapted by David Beazley for his excellent SWIG paper in Proceedings,
%   Tcl 96
% turned into a smartass generic template by De Clarke, with thanks to
%   both the above pioneers
% use at your own risk.  Complaints to /dev/null.
% make it two column with no page numbering, default is 10 point

% Munged by Fred Douglis <douglis@research.att.com> 10/97 to separate
% the .sty file from the LaTeX source template, so that people can
% more easily include the .sty file into an existing document.  Also
% changed to more closely follow the style guidelines as represented
% by the Word sample file. 

% Note that since 2010, USENIX does not require endnotes. If you want
% foot of page notes, don't include the endnotes package in the 
% usepackage command, below.

%----------------------------------------------------------------------------------------
%	PACKAGES & CONFIG
%----------------------------------------------------------------------------------------

%\documentclass[paper=a4, fontsize=11pt]{article} % A4 paper and 11pt font size
\documentclass[letterpaper,twocolumn,10pt]{article}

\usepackage{usenix,epsfig,endnotes}
\usepackage[T1]{fontenc} % Use 8-bit encoding that has 256 glyphs
\usepackage[english]{babel} % English language/hyphenation
\usepackage{amsmath,amsfonts,amsthm} % Math packages
\usepackage{listings} % source code package
\usepackage{tikz} % graph package
\usepackage{supertabular} % table span multiple pages
\usetikzlibrary{shapes,arrows}
\usepackage{courier}
\usepackage[hyphens]{url} %for showing urls in bibliography
%\usepackage{hyperref} %for breaking urls in bib
%\hypersetup{colorlinks=true,breaklinks=true} %for showing urls

%\usepackage{sectsty} % Allows customizing section commands
%\allsectionsfont{\centering \normalfont\scshape} % Make all sections centered, the default font and small caps
%\setlength\parindent{0pt} % Removes all indentation from paragraphs

\newtheorem{theorem}{Theorem}[section]

%----------------------------------------------------------------------------------------
%	TITLE
%----------------------------------------------------------------------------------------
\usepackage{titling}
\newcommand{\subtitle}[1]{%
  \posttitle{%
    \par\end{center}
    \begin{center}\large#1\end{center}
    \vskip0.5em}%
}

\begin{document}

%make title bold and 14 pt font (Latex default is non-bold, 16 pt)
\title{\Large \bf AI Project}
\subtitle{\textit{Subtitle - Project 2014}}


\author{
{\rm Gianluca Barbon}\\
818453@stud.unive.it
%\and
}

%\date{July 24, 2014}
\maketitle

% Use the following at camera-ready time to suppress page numbers.
% Comment it out when you first submit the paper for review.
\thispagestyle{empty}


%\subsection*{Abstract}
\begin{abstract}
\emph{This report describes the artificial intelligence course project. This project consists in the implementation of a Hopfield Network using python. The weight matrix will be computed by using different algorithms, in such a way to analyse performances and thus identify the best solution.}
\end{abstract}

%----------------------------------------------------------------------------------------
%	1. Introduction
%----------------------------------------------------------------------------------------

\section{Introduction}

\subsection{Neural Networks}
They are used for recognition and classification problem, they are capable to learn and so to generalize, that is produce outputs in correspondence of inputs never met before. The training of the net take place presenting a training set (set of example) as input. The answer given by the net for each example will be compared to the desired answer, the difference (or error) between the two will be evaluated and finally the weights will be adjusted by looking at this difference. the process is repeated for the entire training set, until the produced error is minimized, so under a preset threshold.

\subsubsection{Classification Problems}
Classification problems consists in the classification of an object by looking at its features.

\subsection{Hopfield Network}
Hopfield networks are neural networks that can be seen as non linear dynamic systems. They are also called recurring networks or feedback networks. 
We consider neural networks as non linear dynamic systems, where we consider the time variable. In order to do this, we must take into account loops, so we will use recurrent networks.
recurrent networks with non linear units are difficult to analyse: they can converge to a stable state, oscillate or follow chaotic trajectories whose behaviour is not predictable.
However, the american physicist J.J. Hopfield discovered that with symmetric connections there will exist a stable global energy function.
The Hopfield networks have the following properties:
\begin{itemize}
\item\textbf{sigle layer recurrent networks} in which each neuron is connected to all the others, with the exception of itself (so no cycles are admitted)
\item\textbf{symmetric:} the synaptic weight matrix is symmetric, so W=Wt. This means that the weights is the same in both direction between two neurons.
\item\textbf{not linear:} in the continuous formulation, each neuron has a non linear invertible activation function
\end{itemize}
As for the neuron update, we can use three possible approaches:
\begin{itemize}
\item\textbf{asynchronous update:} where neurons are updated one by one
\item\textbf{synchronous update:} all neurons are updated at the same moment
\item\textbf{continuous update:} all neurons are updated in a continuous way
\end{itemize}
There exists two formulation of the Hopfield model: the discrete one and the continuous one, that differ for the way in which the time flows.
For this project we will use the discrete model. In this model the time flows in discrite way and neurons updates in asynchronous way. as for the neuron input, the McCulloch and Pitts model is used, with the adding of an external influence (or bias?) factor. (formula) The activation function is the following (formula). The update of the neurons is a random process and the selection of the unit to be updated can be done in two ways:
\begin{enumerate}
\item at each time instant the unit to be updated is chosen randomly (this mode is useful in simulations)
\item each unit is updated independently with constant probability at each time instant
\end{enumerate}
Unlike feedforward networks, a Hopfield network is a dynamic system. It starts from an initial state (formula) and evolves through a trajectory until it reach a fixed point in which $V(t+1)=V(t)$ (convergence). (immagine) The convergence is granted thanks to an energy function E that govern the systems (formula) and thanks to the Hopfield theorem, that supply a sufficient condition for the convergence of the system.
\begin{theorem}[Hopfield theorem: discrete case]
If the weights matrix in a Hopfield network is symmetric, $\textsf{diag}(W)=0$, the Energy Function will be a Lyapunov function for the system, so 
\begin{center}
$\Delta E = E(t+1)-E(t)\leq 0$
\end{center}
with the equivalence when the system reach a stationary point.
\end{theorem}


%----------------------------------------------------------------------------------------
%	x. Conclusions
%----------------------------------------------------------------------------------------

\section{Conclusions}

\subsection{Future developments}
\cite{example} 

%----------------------------------------------------------------------------------------
%	NOTES AND BIBLIOGRAPHY
%----------------------------------------------------------------------------------------

{\footnotesize \bibliographystyle{acm}
\bibliography{biblio}
}

%\theendnotes

%column break
\vfill
\break

%----------------------------------------------------------------------------------------
%	APPENDICES
%----------------------------------------------------------------------------------------

\onecolumn
\appendix
\label{app:appendixA}
\lstset{language=Java}  
\section{Appendix: example code}

\subsection{Class test.java}


\label{app:appendixB}
\section{Appendix:}


%----------------------------------------------------------------------------------------
%	END OF DOCUMENT
%----------------------------------------------------------------------------------------

\end{document}







